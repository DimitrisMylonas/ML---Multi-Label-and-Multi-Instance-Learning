{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139fc0ad",
   "metadata": {},
   "source": [
    "<font size=\"4\"></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ae424a",
   "metadata": {},
   "source": [
    "Dataset: DeliciousMIL\n",
    "\n",
    "Source and description: https://archive.ics.uci.edu/ml/datasets/DeliciousMIL%3A+A+Data+Set+for+Multi-Label+Multi-Instance+Learning+with+Instance+Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f0eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.metrics import classification_report, zero_one_loss, coverage_error, label_ranking_loss, label_ranking_average_precision_score, silhouette_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea5993",
   "metadata": {},
   "source": [
    "<h2>Part A</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9dcef",
   "metadata": {},
   "source": [
    "<h3>Dataset loading and preprocessing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c886874",
   "metadata": {},
   "source": [
    "<font size=\"3\">Below we read the four relevant files corresponding to train and test data and labels. Since the data contains indexes of words we vectorize the features with TF-IDF Vectorizer.<br>\n",
    "Finally each document is represented as a bag of words with its corresponding label vector</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff9e898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_A shape: (8251, 8510)\n",
      "X_test_A shape: (3983, 8510)\n",
      "y_train_A shape: (8251, 20)\n",
      "y_test_A shape: (3983, 20)\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "with open(\"data/train-data.dat\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = re.sub('<\\d+>', '', line).strip()\n",
    "        line = re.sub('  +', ' ', line)\n",
    "        train_data.append(line)\n",
    "        \n",
    "with open(\"data/train-label.dat\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        values = line.split(' ')\n",
    "        for value in values:\n",
    "            train_label.append(int(value))\n",
    "\n",
    "with open(\"data/test-data.dat\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = re.sub('<\\d+>', '', line).strip()\n",
    "        line = re.sub('  +', ' ', line)\n",
    "        test_data.append(line)\n",
    "        \n",
    "with open(\"data/test-label.dat\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        values = line.split(' ')\n",
    "        for value in values:\n",
    "            test_label.append(int(value))\n",
    "            \n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_A = vectorizer.fit_transform(train_data)\n",
    "X_test_A = vectorizer.transform(test_data)\n",
    "\n",
    "y_train_A = np.array(train_label).reshape((8251, 20))\n",
    "y_test_A = np.array(test_label).reshape((3983, 20))\n",
    "\n",
    "print(f\"X_train_A shape: {X_train_A.shape}\\n\" +\n",
    "    f\"X_test_A shape: {X_test_A.shape}\\n\" +\n",
    "    f\"y_train_A shape: {y_train_A.shape}\\n\" +\n",
    "    f\"y_test_A shape: {y_test_A.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec847d",
   "metadata": {},
   "source": [
    "<h3>Model training and evaluation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196a05e",
   "metadata": {},
   "source": [
    "<font size=\"3\">We define 3 base estimators, Logistic Regression, Random Forest, and an SVM to use with Binary Relevance (MultiOutputClassifier) and Classifier Chain techniques</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a29da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Logistic Regression', 'Random Forest', 'Linear SVM']\n",
    "estimators = [LogisticRegression(class_weight='balanced', random_state=1361),\n",
    "             RandomForestClassifier(criterion = 'entropy', class_weight='balanced',  random_state = 1361),\n",
    "             SVC(kernel='linear', class_weight='balanced', max_iter = 10000, probability = True, random_state = 1361)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e726ef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Relevnace with Logistic Regression estimator:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75       977\n",
      "           1       0.39      0.62      0.48       228\n",
      "           2       0.57      0.61      0.59      1558\n",
      "           3       0.53      0.72      0.61       372\n",
      "           4       0.56      0.68      0.61      1050\n",
      "           5       0.34      0.58      0.43       537\n",
      "           6       0.38      0.68      0.49       702\n",
      "           7       0.54      0.62      0.58      1079\n",
      "           8       0.49      0.65      0.56       803\n",
      "           9       0.49      0.64      0.55       483\n",
      "          10       0.44      0.62      0.52       507\n",
      "          11       0.42      0.59      0.49       478\n",
      "          12       0.36      0.60      0.45       509\n",
      "          13       0.37      0.59      0.45       355\n",
      "          14       0.42      0.66      0.51       392\n",
      "          15       0.37      0.63      0.47       441\n",
      "          16       0.34      0.62      0.44       269\n",
      "          17       0.45      0.56      0.50       501\n",
      "          18       0.47      0.63      0.54       207\n",
      "          19       0.39      0.56      0.46       133\n",
      "\n",
      "   micro avg       0.47      0.64      0.54     11581\n",
      "   macro avg       0.45      0.63      0.52     11581\n",
      "weighted avg       0.49      0.64      0.55     11581\n",
      " samples avg       0.47      0.62      0.50     11581\n",
      "\n",
      "Subset Accuracy: 0.04\n",
      "Coverage Error: 6.85\n",
      "Ranking Loss: 0.13\n",
      "Average Precision: 0.71\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Binary Relevnace with Random Forest estimator:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.48      0.61       977\n",
      "           1       0.89      0.11      0.19       228\n",
      "           2       0.67      0.31      0.43      1558\n",
      "           3       0.94      0.14      0.24       372\n",
      "           4       0.80      0.22      0.35      1050\n",
      "           5       0.62      0.01      0.03       537\n",
      "           6       0.64      0.06      0.11       702\n",
      "           7       0.81      0.20      0.32      1079\n",
      "           8       0.76      0.19      0.31       803\n",
      "           9       0.84      0.17      0.28       483\n",
      "          10       0.85      0.09      0.16       507\n",
      "          11       0.76      0.06      0.11       478\n",
      "          12       0.50      0.01      0.02       509\n",
      "          13       0.85      0.11      0.20       355\n",
      "          14       0.81      0.12      0.21       392\n",
      "          15       0.53      0.04      0.07       441\n",
      "          16       0.71      0.02      0.04       269\n",
      "          17       0.80      0.08      0.15       501\n",
      "          18       0.91      0.14      0.24       207\n",
      "          19       0.75      0.05      0.09       133\n",
      "\n",
      "   micro avg       0.77      0.17      0.28     11581\n",
      "   macro avg       0.77      0.13      0.21     11581\n",
      "weighted avg       0.75      0.17      0.26     11581\n",
      " samples avg       0.34      0.17      0.21     11581\n",
      "\n",
      "Subset Accuracy: 0.08\n",
      "Coverage Error: 7.29\n",
      "Ranking Loss: 0.14\n",
      "Average Precision: 0.68\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Binary Relevnace with Linear SVM estimator:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74       977\n",
      "           1       0.44      0.55      0.49       228\n",
      "           2       0.56      0.61      0.59      1558\n",
      "           3       0.54      0.70      0.61       372\n",
      "           4       0.53      0.66      0.59      1050\n",
      "           5       0.31      0.56      0.40       537\n",
      "           6       0.36      0.58      0.45       702\n",
      "           7       0.51      0.61      0.56      1079\n",
      "           8       0.46      0.63      0.53       803\n",
      "           9       0.46      0.61      0.52       483\n",
      "          10       0.40      0.57      0.47       507\n",
      "          11       0.41      0.52      0.46       478\n",
      "          12       0.33      0.56      0.42       509\n",
      "          13       0.36      0.53      0.43       355\n",
      "          14       0.46      0.61      0.52       392\n",
      "          15       0.36      0.54      0.43       441\n",
      "          16       0.39      0.49      0.44       269\n",
      "          17       0.46      0.52      0.49       501\n",
      "          18       0.61      0.53      0.57       207\n",
      "          19       0.49      0.47      0.48       133\n",
      "\n",
      "   micro avg       0.46      0.61      0.53     11581\n",
      "   macro avg       0.46      0.58      0.51     11581\n",
      "weighted avg       0.48      0.61      0.53     11581\n",
      " samples avg       0.46      0.59      0.48     11581\n",
      "\n",
      "Subset Accuracy: 0.04\n",
      "Coverage Error: 7.18\n",
      "Ranking Loss: 0.14\n",
      "Average Precision: 0.69\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, est in zip(names, estimators):\n",
    "    print(f\"Binary Relevnace with {name} estimator:\\n\")\n",
    "    clf = MultiOutputClassifier(est)\n",
    "    clf.fit(X_train_A, y_train_A)\n",
    "    y_pred = clf.predict(X_test_A)\n",
    "    y_proba = np.array([[k[1] for k in i] for i in clf.predict_proba(X_test_A)]).T\n",
    "    \n",
    "    print(classification_report(y_test_A, y_pred, zero_division='warn'))\n",
    "    print(f\"Subset Accuracy: {1-zero_one_loss(y_test_A, y_pred):.2f}\")\n",
    "    print(f\"Coverage Error: {coverage_error(y_test_A, y_proba):.2f}\")\n",
    "    print(f\"Ranking Loss: {label_ranking_loss(y_test_A, y_proba):.2f}\")\n",
    "    print(f\"Average Precision: {label_ranking_average_precision_score(y_test_A, y_proba):.2f}\")\n",
    "    print(\"----------------------------------------------------------------------------\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93965fe9",
   "metadata": {},
   "source": [
    "<font size=\"3\">Binary Relevnace evaluation based on macro averaged f1 score: \n",
    "  * BR with Logistic Regression: 0.52\n",
    "  * BR with Random Forest: 0.21\n",
    "  * BR with SVC: 0.51 \n",
    "<br><br>\n",
    "Logistic Regression and SVC produce similar results, while Random Forest preforms significantly worse</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec5e125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Chain with Logistic Regression estimator:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75       977\n",
      "           1       0.40      0.63      0.49       228\n",
      "           2       0.57      0.61      0.59      1558\n",
      "           3       0.43      0.77      0.55       372\n",
      "           4       0.56      0.66      0.61      1050\n",
      "           5       0.33      0.51      0.40       537\n",
      "           6       0.36      0.70      0.48       702\n",
      "           7       0.49      0.64      0.56      1079\n",
      "           8       0.46      0.66      0.54       803\n",
      "           9       0.41      0.65      0.50       483\n",
      "          10       0.37      0.64      0.47       507\n",
      "          11       0.31      0.68      0.42       478\n",
      "          12       0.32      0.57      0.41       509\n",
      "          13       0.27      0.66      0.38       355\n",
      "          14       0.33      0.71      0.45       392\n",
      "          15       0.28      0.64      0.39       441\n",
      "          16       0.23      0.64      0.34       269\n",
      "          17       0.38      0.58      0.46       501\n",
      "          18       0.26      0.68      0.37       207\n",
      "          19       0.20      0.76      0.32       133\n",
      "\n",
      "   micro avg       0.41      0.66      0.50     11581\n",
      "   macro avg       0.38      0.66      0.47     11581\n",
      "weighted avg       0.44      0.66      0.52     11581\n",
      " samples avg       0.41      0.63      0.46     11581\n",
      "\n",
      "Subset Accuracy: 0.04\n",
      "Coverage Error: 7.23\n",
      "Ranking Loss: 0.15\n",
      "Average Precision: 0.66\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Classifier Chain with Random Forest estimator:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.48      0.61       977\n",
      "           1       0.86      0.08      0.15       228\n",
      "           2       0.67      0.28      0.40      1558\n",
      "           3       0.91      0.21      0.34       372\n",
      "           4       0.79      0.19      0.30      1050\n",
      "           5       0.62      0.01      0.03       537\n",
      "           6       0.62      0.04      0.08       702\n",
      "           7       0.82      0.17      0.28      1079\n",
      "           8       0.70      0.18      0.29       803\n",
      "           9       0.89      0.15      0.26       483\n",
      "          10       0.79      0.07      0.13       507\n",
      "          11       0.76      0.05      0.09       478\n",
      "          12       0.55      0.01      0.02       509\n",
      "          13       0.90      0.10      0.18       355\n",
      "          14       0.90      0.14      0.24       392\n",
      "          15       0.60      0.03      0.05       441\n",
      "          16       0.62      0.02      0.04       269\n",
      "          17       0.85      0.07      0.13       501\n",
      "          18       0.91      0.15      0.26       207\n",
      "          19       0.71      0.04      0.07       133\n",
      "\n",
      "   micro avg       0.77      0.16      0.27     11581\n",
      "   macro avg       0.77      0.12      0.20     11581\n",
      "weighted avg       0.75      0.16      0.25     11581\n",
      " samples avg       0.30      0.16      0.19     11581\n",
      "\n",
      "Subset Accuracy: 0.08\n",
      "Coverage Error: 7.36\n",
      "Ranking Loss: 0.14\n",
      "Average Precision: 0.67\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Classifier Chain with Linear SVM estimator:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74       977\n",
      "           1       0.45      0.54      0.49       228\n",
      "           2       0.56      0.61      0.58      1558\n",
      "           3       0.51      0.73      0.60       372\n",
      "           4       0.53      0.66      0.59      1050\n",
      "           5       0.31      0.55      0.40       537\n",
      "           6       0.36      0.62      0.46       702\n",
      "           7       0.49      0.64      0.56      1079\n",
      "           8       0.46      0.63      0.53       803\n",
      "           9       0.46      0.63      0.53       483\n",
      "          10       0.40      0.57      0.47       507\n",
      "          11       0.37      0.58      0.45       478\n",
      "          12       0.31      0.57      0.40       509\n",
      "          13       0.33      0.56      0.41       355\n",
      "          14       0.42      0.64      0.51       392\n",
      "          15       0.33      0.55      0.42       441\n",
      "          16       0.35      0.51      0.41       269\n",
      "          17       0.44      0.50      0.47       501\n",
      "          18       0.56      0.50      0.53       207\n",
      "          19       0.34      0.53      0.41       133\n",
      "\n",
      "   micro avg       0.45      0.62      0.52     11581\n",
      "   macro avg       0.43      0.60      0.50     11581\n",
      "weighted avg       0.46      0.62      0.53     11581\n",
      " samples avg       0.45      0.60      0.47     11581\n",
      "\n",
      "Subset Accuracy: 0.04\n",
      "Coverage Error: 7.18\n",
      "Ranking Loss: 0.14\n",
      "Average Precision: 0.69\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, est in zip(names, estimators):\n",
    "    print(f\"Classifier Chain with {name} estimator:\\n\")\n",
    "    clf = ClassifierChain(est)\n",
    "    clf.fit(X_train_A, y_train_A)\n",
    "    y_pred = clf.predict(X_test_A)\n",
    "    y_proba = clf.predict_proba(X_test_A)\n",
    "    \n",
    "    print(classification_report(y_test_A, y_pred, zero_division='warn'))\n",
    "    print(f\"Subset Accuracy: {1-zero_one_loss(y_test_A, y_pred):.2f}\")\n",
    "    print(f\"Coverage Error: {coverage_error(y_test_A, y_proba):.2f}\")\n",
    "    print(f\"Ranking Loss: {label_ranking_loss(y_test_A, y_proba):.2f}\")\n",
    "    print(f\"Average Precision: {label_ranking_average_precision_score(y_test_A, y_proba):.2f}\")\n",
    "    print(\"----------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b79d9",
   "metadata": {},
   "source": [
    "<font size=\"3\">Classifier Chain evaluation based on macro averaged f1 score: \n",
    "  * CC with Logistic Regression: 0.47\n",
    "  * CC with Random Forest: 0.27\n",
    "  * CC with SVC: 0.50 \n",
    "<br><br>\n",
    "Logistic Regression and SVC produce similar results, while Random Forest preforms significantly worse</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d07b4",
   "metadata": {},
   "source": [
    "<h2>Part B</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d4c8d3",
   "metadata": {},
   "source": [
    "<h3>Dataset loading and preprocessing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3691fe2",
   "metadata": {},
   "source": [
    "<font size=3>Out of the 20 classes we isolate the most frequent one (based on the training set) to transform the multi-class problem into a binary classification problem</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b93728",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_class = np.argmax(np.sum(y_train_A, axis=0))\n",
    "\n",
    "y_train_Β = y_train_A[:,most_freq_class]\n",
    "y_test_Β = y_test_A[:,most_freq_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa6d17",
   "metadata": {},
   "source": [
    "<font size=3>In this approach, each document is a bag of sentences. We created 2 dataframes (one for the training set and one for the test set to better visualize the problem representation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c60a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_count = 0\n",
    "index_count = 0\n",
    "bag_of_sentences = {}\n",
    "\n",
    "with open(\"data/train-data.dat\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line, label in zip(lines, y_train_Β):\n",
    "        line = re.split('<\\d+>', line)\n",
    "        for sentence in line:\n",
    "            sentence = sentence.strip()\n",
    "            \n",
    "            if sentence:\n",
    "                bag_of_sentences[index_count] = (doc_count, sentence.strip(), label)\n",
    "                index_count += 1\n",
    "                \n",
    "        doc_count += 1\n",
    "        \n",
    "data_train_B_DF = pd.DataFrame.from_dict(bag_of_sentences, columns = ['Bag', 'Sentence', 'Target'], orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97299e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_count = 0\n",
    "index_count = 0\n",
    "bag_of_sentences = {}\n",
    "\n",
    "with open(\"data/test-data.dat\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line, label in zip(lines, y_test_Β):\n",
    "        line = re.split('<\\d+>', line)\n",
    "        for sentence in line:\n",
    "            sentence = sentence.strip()\n",
    "            \n",
    "            if sentence:\n",
    "                bag_of_sentences[index_count] = (doc_count, sentence.strip(), label)\n",
    "                index_count += 1\n",
    "                \n",
    "        doc_count += 1\n",
    "        \n",
    "data_test_B_DF = pd.DataFrame.from_dict(bag_of_sentences, columns = ['Bag', 'Sentence', 'Target'], orient = 'index')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da65f2",
   "metadata": {},
   "source": [
    "The head and tail of the two dataframes is presented below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ef53591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bag</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6705 5997 8310 3606 674 8058 5044 4836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4312 5154 8310 4225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1827 1037 8482 483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3567 6172 6172 2892 1362 787 399 777 1332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>318 769 4621 3199 1480 6213 971 6890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5909 15 3445 2475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>324 4138 3404 6176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>65 2926 1375 7705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>709 1323 1652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>5735 7439 3445 2475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bag                                   Sentence  Target\n",
       "0    0     6705 5997 8310 3606 674 8058 5044 4836       1\n",
       "1    0                        4312 5154 8310 4225       1\n",
       "2    1                         1827 1037 8482 483       1\n",
       "3    1  3567 6172 6172 2892 1362 787 399 777 1332       1\n",
       "4    1       318 769 4621 3199 1480 6213 971 6890       1\n",
       "5    1                          5909 15 3445 2475       1\n",
       "6    1                         324 4138 3404 6176       1\n",
       "7    1                          65 2926 1375 7705       1\n",
       "8    1                              709 1323 1652       1\n",
       "9    1                        5735 7439 3445 2475       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_B_DF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "802db978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bag</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149915</th>\n",
       "      <td>8248</td>\n",
       "      <td>3700 2415 6171 2374 4711 5280 5071 1319 6559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149916</th>\n",
       "      <td>8248</td>\n",
       "      <td>793 114 246 114 5071 5378 2738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149917</th>\n",
       "      <td>8249</td>\n",
       "      <td>7658 8174 3492 246 4015 764 327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149918</th>\n",
       "      <td>8249</td>\n",
       "      <td>2023 874 6309 235 7102 8132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149919</th>\n",
       "      <td>8249</td>\n",
       "      <td>568 2179 1620 4403 1035 6651 1035 7845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149920</th>\n",
       "      <td>8249</td>\n",
       "      <td>1386 384 4282 2229 5349 7139 5663 5742 4282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149921</th>\n",
       "      <td>8249</td>\n",
       "      <td>6008 1758 5682 2263 7699 4700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149922</th>\n",
       "      <td>8250</td>\n",
       "      <td>6072 1632 6587 2623 1178 6078 345 2651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149923</th>\n",
       "      <td>8250</td>\n",
       "      <td>1281 3041 2797 6144 2276 5149 4621 1890 2276 5506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149924</th>\n",
       "      <td>8250</td>\n",
       "      <td>8082 2514 5110 1319 5154 8334 2044 677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Bag                                           Sentence  Target\n",
       "149915  8248       3700 2415 6171 2374 4711 5280 5071 1319 6559       0\n",
       "149916  8248                     793 114 246 114 5071 5378 2738       0\n",
       "149917  8249                    7658 8174 3492 246 4015 764 327       1\n",
       "149918  8249                        2023 874 6309 235 7102 8132       1\n",
       "149919  8249             568 2179 1620 4403 1035 6651 1035 7845       1\n",
       "149920  8249        1386 384 4282 2229 5349 7139 5663 5742 4282       1\n",
       "149921  8249                      6008 1758 5682 2263 7699 4700       1\n",
       "149922  8250             6072 1632 6587 2623 1178 6078 345 2651       0\n",
       "149923  8250  1281 3041 2797 6144 2276 5149 4621 1890 2276 5506       0\n",
       "149924  8250             8082 2514 5110 1319 5154 8334 2044 677       0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_B_DF.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20ec0195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bag</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5282 4641 3031 536 5366 1759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4855 1037 7752 2287 1090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1921 6213 3292 5750 6068 5648 1444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6157 1574 6955 2287 3816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5553 568 6955 5523 2793 4312 2033 4217 7593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>6955 965 7553</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>7464 2651 8283 1426 5741 4032 740</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>470 2413 4767 6629 4551 7859 1007 6629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>945 7553 4551 6955 568 7981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>4386 6166 539 8115 6183 7440 1137 6 1137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bag                                     Sentence  Target\n",
       "0    0                 5282 4641 3031 536 5366 1759       1\n",
       "1    0                     4855 1037 7752 2287 1090       1\n",
       "2    0           1921 6213 3292 5750 6068 5648 1444       1\n",
       "3    0                     6157 1574 6955 2287 3816       1\n",
       "4    0  5553 568 6955 5523 2793 4312 2033 4217 7593       1\n",
       "5    0                                6955 965 7553       1\n",
       "6    0            7464 2651 8283 1426 5741 4032 740       1\n",
       "7    0       470 2413 4767 6629 4551 7859 1007 6629       1\n",
       "8    0                  945 7553 4551 6955 568 7981       1\n",
       "9    0     4386 6166 539 8115 6183 7440 1137 6 1137       1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_B_DF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32547c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bag</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73353</th>\n",
       "      <td>3980</td>\n",
       "      <td>682 674 3648 971 3664 980 1564 1551 8487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73354</th>\n",
       "      <td>3980</td>\n",
       "      <td>3031 7752 1914 3994 2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73355</th>\n",
       "      <td>3980</td>\n",
       "      <td>8424 1145 1657 2975 7195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73356</th>\n",
       "      <td>3980</td>\n",
       "      <td>3292 3997 4812 345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73357</th>\n",
       "      <td>3981</td>\n",
       "      <td>2781 3368 3672 704 5667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73358</th>\n",
       "      <td>3981</td>\n",
       "      <td>5978 3031 4466 483 3405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73359</th>\n",
       "      <td>3981</td>\n",
       "      <td>4466 4081 4621 474 5970 1259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73360</th>\n",
       "      <td>3982</td>\n",
       "      <td>1209 6858 1137 4466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73361</th>\n",
       "      <td>3982</td>\n",
       "      <td>859 444 1037 859 444 8482 4466 8482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73362</th>\n",
       "      <td>3982</td>\n",
       "      <td>7679 2287 2568 3896 2035 728 5817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bag                                  Sentence  Target\n",
       "73353  3980  682 674 3648 971 3664 980 1564 1551 8487       0\n",
       "73354  3980                  3031 7752 1914 3994 2833       0\n",
       "73355  3980                  8424 1145 1657 2975 7195       0\n",
       "73356  3980                        3292 3997 4812 345       0\n",
       "73357  3981                   2781 3368 3672 704 5667       0\n",
       "73358  3981                   5978 3031 4466 483 3405       0\n",
       "73359  3981              4466 4081 4621 474 5970 1259       0\n",
       "73360  3982                       1209 6858 1137 4466       1\n",
       "73361  3982       859 444 1037 859 444 8482 4466 8482       1\n",
       "73362  3982         7679 2287 2568 3896 2035 728 5817       1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_B_DF.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89403d1",
   "metadata": {},
   "source": [
    "<font size = 3>We take each instance (sentence) from the dataframe and add it to a new list. Then we vectorize based on the train list to create 2 new datasets, the train and the test</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "224e6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bags = []\n",
    "test_bags = []\n",
    "\n",
    "for index, value in data_train_B_DF['Sentence'].items():\n",
    "    train_bags.append(value)\n",
    "    \n",
    "for index, value in data_test_B_DF['Sentence'].items():\n",
    "    test_bags.append(value)\n",
    "    \n",
    "vectorizer = TfidfVectorizer()\n",
    "train_bags_transformed = vectorizer.fit_transform(train_bags)\n",
    "test_bags_transformed = vectorizer.transform(test_bags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6083ebe",
   "metadata": {},
   "source": [
    "<font size=3>We use the silhouette method to determine the optimal number of clusters for our clustering algorithm</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e9bcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "sil_score = []\n",
    "kmax = 40\n",
    "x = train_bags_transformed\n",
    "\n",
    "for k in range(2, kmax + 1):\n",
    "    kmeans = KMeans(n_clusters = k, random_state = 1361).fit(x)\n",
    "    labels = kmeans.labels_\n",
    "    sil_score.append(silhouette_score(x, labels, metric = 'cosine'))\n",
    "    \n",
    "best_k = np.argmax(sil_score) + 2\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5cdd0",
   "metadata": {},
   "source": [
    "<font size=3>We perform k-means clustering with k=39. Those 39 clusters will become our features for the next step</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e0507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters = best_k, random_state = 1361)\n",
    "model.fit(train_bags_transformed)\n",
    "\n",
    "train_predictions = model.predict(train_bags_transformed)\n",
    "test_predictions = model.predict(test_bags_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db4fde3",
   "metadata": {},
   "source": [
    "<font size=3>For every instance of every bag, we find the cluster it belongs to and add 1 to that feature. After that we get our new train and test set with features representing all of the instances of each bag</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42adbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_B = np.zeros((8251, best_k), dtype=np.int32)\n",
    "X_test_B = np.zeros((3983, best_k), dtype=np.int32)\n",
    "\n",
    "train_bag_num = data_train_B_DF['Bag'].to_numpy()\n",
    "test_bag_num = data_test_B_DF['Bag'].to_numpy()\n",
    "\n",
    "for bag, prediction in zip(train_bag_num, train_predictions):\n",
    "    X_train_B[bag, prediction] += 1\n",
    "    \n",
    "for bag, prediction in zip(test_bag_num, test_predictions):\n",
    "    X_test_B[bag, prediction] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd28fdb",
   "metadata": {},
   "source": [
    "<font size=3>We train a Random Forest Classifier, once on our multi-instance training set and once on our training set from <b>Part A</b> and we evaluate our models on our test set with only the most frequent class (binary classification)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0477dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with k-means (multi-instance)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.82      0.73      2425\n",
      "           1       0.54      0.32      0.40      1558\n",
      "\n",
      "    accuracy                           0.63      3983\n",
      "   macro avg       0.59      0.57      0.56      3983\n",
      "weighted avg       0.61      0.63      0.60      3983\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Random Forest\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      2425\n",
      "           1       0.67      0.31      0.43      1558\n",
      "\n",
      "    accuracy                           0.67      3983\n",
      "   macro avg       0.67      0.61      0.60      3983\n",
      "weighted avg       0.67      0.67      0.63      3983\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion = 'entropy', class_weight='balanced',  random_state = 1361)\n",
    "\n",
    "print(f\"Random Forest with k-means (multi-instance)\\n\")\n",
    "clf.fit(X_train_B, y_train_Β)\n",
    "y_pred = clf.predict(X_test_B)\n",
    "\n",
    "print(classification_report(y_test_Β, y_pred))\n",
    "print(\"----------------------------------------------------------------------------\\n\")\n",
    "\n",
    "print(f\"Random Forest\\n\")\n",
    "clf.fit(X_train_A, y_train_Β)\n",
    "y_pred = clf.predict(X_test_A)\n",
    "\n",
    "print(classification_report(y_test_Β, y_pred))\n",
    "print(\"----------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3f7e1",
   "metadata": {},
   "source": [
    "<font size=3>Evaluation: \n",
    "  * Multi-instance RF accuracy: 0.63\n",
    "  * Multi-instance RF precision: 0.59\n",
    "  * Multi-instance RF recall: 0.57\n",
    "  * Multi-instance RF f1-score: 0.56\n",
    "<br><br>\n",
    "  * RF accuracy: 0.67\n",
    "  * RF precision: 0.67\n",
    "  * RF recall: 0.61\n",
    "  * RF f1-score: 0.60  \n",
    "<br><br>\n",
    "<font size=4>On all metrics the random forest classifier performed worse on the multi-instance data</font></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
